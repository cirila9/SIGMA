{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.cuda.amp as amp\n",
    "import torch.optim as optim\n",
    "from torchvision.ops import *\n",
    "from torchvision.models import *\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "# import bitsandbytes as bnb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device('cuda:0')\n",
    "# device1 = torch.device('cuda:1')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def split_targets(targets):\n",
    "    cores = cpu_count()\n",
    "    part = len(targets)//cores\n",
    "    \n",
    "    parts = []\n",
    "    for i in range(cores-1):\n",
    "        temp = targets[i*part: (i+1)*part]\n",
    "        parts.append(temp)\n",
    "    parts.append(targets[(i+1)*part:])\n",
    "    return parts, cores\n",
    "    \n",
    "# Gather Expression dataset\n",
    "def GenData(paras):  # (gene_part, sub_tf, sub_tf_exp, genesexp_part, sub_gold, time_lag)\n",
    "    error = 0\n",
    "    all_tf, all_target = [], []\n",
    "    gene_pair, exp_pair, labels = [], [], []\n",
    "    tfs, targets, exp, gold, core = paras\n",
    "    \n",
    "    if core == 1:\n",
    "        for i in trange(len(tfs)):\n",
    "            tf = tfs[i]\n",
    "            tf_exp = exp[tf]\n",
    "            for target in targets:\n",
    "                target_exp = exp[target]\n",
    "                relation = [tf, target]\n",
    "                gene_pair.append(relation)\n",
    "                exp_pair.append(np.vstack((tf_exp, target_exp)))\n",
    "                if relation in gold:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    else:\n",
    "        for tf in tfs:\n",
    "            tf_exp = exp[tf]\n",
    "            for target in targets:\n",
    "                target_exp = exp[target]\n",
    "                relation = [tf, target]\n",
    "                gene_pair.append(relation)\n",
    "                exp_pair.append(np.vstack((tf_exp, target_exp)))\n",
    "                if relation in gold:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    return (gene_pair, exp_pair, labels)\n",
    "\n",
    "def processing(tf_raw, gene_raw, exp, gold):\n",
    "    print('Multi-core processing...')\n",
    "    start = time.time()\n",
    "    if __name__ == '__main__':\n",
    "        tf = np.intersect1d(tf_raw, gold[:,0].reshape(-1,))\n",
    "        targets = np.intersect1d(gene_raw, gold[:,1].reshape(-1,))\n",
    "        print('num of tfs:', len(tf), 'num of targets:', len(targets))\n",
    "        \n",
    "        # targets_part, cores = split_targets(targets) \n",
    "        # gene_pair, all_exp, all_labels = [], [], []\n",
    "        # p = ProcessPoolExecutor(max_workers=cores)\n",
    "        # process = [p.submit(GenData, (tf, targets_part[i], exp, gold.tolist(), i)) for i in range(cores)]\n",
    "        # p.shutdown()\n",
    "        # for j in range(cores):\n",
    "        #     results = process[j].result()\n",
    "        #     gene_pair.extend(results[0])\n",
    "        #     all_exp.extend(results[1])\n",
    "        #     all_labels.extend(results[2])\n",
    "\n",
    "        gene_pair, all_exp, all_labels = GenData((tf, targets, exp, gold.tolist(), 1))\n",
    "\n",
    "        end = time.time()\n",
    "        RuningTime = end - start\n",
    "        print('multiprocessing Done! Runing Time:', round(RuningTime / 60, 2), 'sec')\n",
    "\n",
    "    return gene_pair, all_exp, all_labels\n",
    "\n",
    "def split_datasets(labels):\n",
    "    print('labels', np.sum(labels))\n",
    "    pos_index, neg_index = [], []\n",
    "    pos_index = [index for index, value in enumerate(labels) if value == 1]\n",
    "    neg_index = [index for index, value in enumerate(labels) if value == 0]\n",
    "    pos_shuffle, neg_shuffle = random.sample(pos_index, len(pos_index)), random.sample(neg_index, len(neg_index))\n",
    "    pos_part, neg_part = len(pos_shuffle) // 5, len(neg_shuffle) // 5\n",
    "    pos_train, neg_train = pos_shuffle[ :3*pos_part], neg_shuffle[ :3*neg_part]\n",
    "    pos_val, neg_val = pos_shuffle[3*pos_part : 4*pos_part], neg_shuffle[3*neg_part : 4*neg_part]\n",
    "    pos_test, neg_test = pos_shuffle[4*pos_part: ], neg_shuffle[4*neg_part: ]\n",
    "    train_index = pos_train + neg_train\n",
    "    val_index = pos_val + neg_val\n",
    "    test_index = pos_test + neg_test\n",
    "\n",
    "    return train_index, val_index, test_index\n",
    "\n",
    "\n",
    "\n",
    "# Gather Expression dataset\n",
    "class Feeder(Dataset):\n",
    "    def __init__(self, exp_data, label, patch_size, mode='pretrain', base=128):\n",
    "        assert mode=='pretrain' or mode=='lincls', 'mode should in [pretrain, lincls]'\n",
    "\n",
    "        self.exp_data = exp_data[:, :, :exp_data.shape[-1]-exp_data.shape[-1] % patch_size]\n",
    "        self.label = label\n",
    "        self.arange = np.arange(exp_data.shape[-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tf, target = copy.deepcopy(self.exp_data[index][0]), copy.deepcopy(self.exp_data[index][1])\n",
    "        label = self.label[index]\n",
    "        \n",
    "        X = np.concatenate([tf.reshape(1,-1), target.reshape(1,-1)], axis=0).astype(np.float16)\n",
    "        return X, label\n",
    "    \n",
    "batch_size = 512\n",
    "patch_size = 8\n",
    "\n",
    "ExpressionData = pd.read_csv('../Benchmark Dataset/Non-Specific Dataset/hESC/TFs+1000/BL--ExpressionData.csv', index_col=0, engine='c')\n",
    "network = pd.read_csv('../Benchmark Dataset/Non-Specific Dataset/hESC/TFs+1000/Label.csv', index_col=0, engine='c').values\n",
    "tfs_raw = pd.read_csv('../Benchmark Dataset/Non-Specific Dataset/hESC/TFs+1000/TF.csv', index_col=0, engine='c')['index'].values.tolist()\n",
    "targets_raw = pd.read_csv('../Benchmark Dataset/Non-Specific Dataset/hESC/TFs+1000/Target.csv', index_col=0, engine='c')['index'].values.tolist()\n",
    "\n",
    "gene_pair, all_exp, labels = processing(tfs_raw, targets_raw, ExpressionData.values, network)\n",
    "\n",
    "data = Feeder(np.array(all_exp), labels, patch_size, 'pretrain')\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "labels_unique, counts = np.unique(labels, return_counts=True)\n",
    "class_weight = [sum(counts)/i for i in counts]\n",
    "print('labels', np.sum(labels), 'postive VS negative:', class_weight, 'Density:', round(class_weight[0]/sum(class_weight), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes\n",
    "from einops import rearrange, repeat, pack, unpack\n",
    "from einops.layers.torch import Rearrange\n",
    "import math\n",
    "        \n",
    "def SinCosEmbed(seq_len, d_model, max_len=5000):\n",
    "    pe = torch.zeros(max_len, d_model).float()\n",
    "    pe.require_grad = False\n",
    "    \n",
    "    position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "    div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "    \n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    pe = pe.unsqueeze(0)\n",
    "    return pe[:, :seq_len, :d_model]\n",
    "\n",
    "class PosEmb(nn.Module):\n",
    "    def __init__(self, num, dim, emb_dropout):\n",
    "        super().__init__()\n",
    "        self.num = num\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.pos_emd = nn.Parameter(SinCosEmbed(num, dim), requires_grad=False)\n",
    "        # self.pos_emd = nn.Parameter(SinCosEmbed(num+1, dim), requires_grad=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        # x = torch.cat((x, cls_tokens), dim=1)\n",
    "        return x + self.dropout(self.pos_emd)\n",
    "        \n",
    "class Logits(nn.Module):\n",
    "    def __init__(self, cls_token=False):\n",
    "        super().__init__()\n",
    "        self.cls_token = cls_token\n",
    "    def forward(self, x):\n",
    "        out = x[:, -1] if self.cls_token else x.mean(dim = 1)\n",
    "        return out\n",
    "\n",
    "class MAE(nn.Module):\n",
    "    def __init__(\n",
    "                self,*,\n",
    "                seq_len, \n",
    "                channels,\n",
    "                patch_size,   \n",
    "                dim = 192, \n",
    "                heads = 12,\n",
    "                mlp_ratio = 4,\n",
    "                cls_token = True,\n",
    "                emded_grad = True,\n",
    "                masking_ratio = 0.7,\n",
    "                # encodoer paraments\n",
    "                encoder_depth = 2, \n",
    "                dropout = .2, \n",
    "                emb_dropout = 0.,\n",
    "                # decoder paraments\n",
    "                decoder_depth = 2, \n",
    "                ):\n",
    "        super().__init__()\n",
    "        assert (seq_len % patch_size) == 0, 'seq_len must be divisible by patch_size'\n",
    "        assert masking_ratio > 0 and masking_ratio < 1, 'masking ratio must be kept between 0 and 1'\n",
    "\n",
    "        self.dim = dim\n",
    "        self.cls = cls_token\n",
    "        self.logits = Logits(cls_token)\n",
    "        self.masking_ratio = masking_ratio\n",
    "        num_patches = seq_len // patch_size * channels\n",
    "        self.to_patch = Rearrange('b c (n p) -> b (c n) p', p = patch_size)\n",
    "        \n",
    "        self.patch_to_emb = nn.Sequential(\n",
    "                                            # nn.LayerNorm(patch_size),\n",
    "                                            nn.Linear(patch_size, dim, bias=False),\n",
    "                                            nn.LayerNorm(dim),\n",
    "                                            PosEmb(num_patches, dim, emb_dropout),\n",
    "                                            )\n",
    "        # xavier_uniform initialization\n",
    "        nn.init.xavier_uniform_(self.patch_to_emb[0].weight)\n",
    "        self.patch_to_emb[0].weight.requires_grad = emded_grad\n",
    "                \n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        \n",
    "        # extract some hyperparameters and functions from encoder\n",
    "        EncoderLayer = nn.TransformerEncoderLayer(d_model=dim, \n",
    "                                                    nhead=heads,\n",
    "                                                    dim_feedforward=int(dim*mlp_ratio),\n",
    "                                                    dropout=dropout, \n",
    "                                                    activation='gelu',\n",
    "                                                    # layer_norm_eps=1e-3,\n",
    "                                                    batch_first=True,\n",
    "                                                    norm_first=True,\n",
    "                                                    )\n",
    "        self.encoder = nn.TransformerEncoder(EncoderLayer, num_layers=encoder_depth)\n",
    "        \n",
    "        # decoder parameters\n",
    "        self.mask_token = nn.Parameter(torch.randn(dim))\n",
    "        DecoderLayer = nn.TransformerEncoderLayer(d_model=dim, \n",
    "                                                    nhead=heads,\n",
    "                                                    dim_feedforward=int(dim*mlp_ratio),\n",
    "                                                    dropout=dropout, \n",
    "                                                    activation='gelu',\n",
    "                                                    # layer_norm_eps=1e-3,\n",
    "                                                    batch_first=True,\n",
    "                                                    norm_first=True,\n",
    "                                                    )\n",
    "        self.decoder = nn.TransformerEncoder(DecoderLayer, num_layers=decoder_depth)\n",
    "        self.decoder_pos_emb = nn.Parameter(SinCosEmbed(num_patches+1, dim), requires_grad=False) if self.cls else nn.Parameter(SinCosEmbed(num_patches, dim), requires_grad=False)\n",
    "        \n",
    "        self.to_seqs = nn.Linear(dim, patch_size)\n",
    "        \n",
    "        # MSE and Cosine Similarity Loss \n",
    "        self.loss = nn.MSELoss()\n",
    "        self.criterion = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, series):\n",
    "        device = series.device\n",
    "\n",
    "        # get patches\n",
    "        patches = self.to_patch(series)\n",
    "        batch, num_patches, *_ = patches.shape\n",
    "\n",
    "        # patch to encoder tokens and add positions\n",
    "        tokens = self.patch_to_emb(patches)\n",
    "\n",
    "        # calculate of patches needed to be masked, and get random indices, dividing it up for mask vs unmasked\n",
    "        num_masked = int(self.masking_ratio * num_patches)\n",
    "\n",
    "        batch_range = torch.arange(batch, device=device)[:, None]\n",
    "        if self.cls:\n",
    "            rand_indices = torch.rand(batch, num_patches+1, device=device)\n",
    "            rand_indices[:, -1] = 1e+7\n",
    "            rand_indices = rand_indices.argsort(dim = -1)\n",
    "        else:\n",
    "            rand_indices = torch.rand(batch, num_patches, device=device).argsort(dim = -1)\n",
    "        masked_indices, unmasked_indices = rand_indices[:, :num_masked], rand_indices[:, num_masked:]\n",
    "\n",
    "        # target feature\n",
    "        z = tokens[batch_range, masked_indices]\n",
    "        z = self.encoder(z).mean(dim=1)\n",
    "        \n",
    "        # get the unmasked tokens to be encoded\n",
    "        tokens = tokens[batch_range, unmasked_indices]\n",
    "\n",
    "        # get the patches to be masked for the final reconstruction loss\n",
    "        masked_patches = patches[batch_range, masked_indices]\n",
    "        \n",
    "        # attend with transformer\n",
    "        encoded_tokens = self.encoder(tokens)\n",
    "\n",
    "        # project encoder to decoder dimensions, if they are not equal\n",
    "        # encoded_tokens += self.decoder_pos_emb[:, unmasked_indices]\n",
    "        encoded_tokens = self.ln(encoded_tokens) + self.decoder_pos_emb[:, unmasked_indices]\n",
    "            \n",
    "        # repeat mask tokens for number of masked, and add the positions using the masked indices derived above\n",
    "        mask_tokens = repeat(self.mask_token, 'd -> b n d', b = batch, n = num_masked)\n",
    "        mask_tokens = mask_tokens + self.decoder_pos_emb[:, masked_indices]\n",
    "        \n",
    "        \n",
    "        # concat the masked tokens to the decoder tokens\n",
    "        if self.cls:\n",
    "            decoder_tokens = torch.zeros(batch, num_patches+1, self.dim, device=device)\n",
    "        else:\n",
    "            decoder_tokens = torch.zeros(batch, num_patches, self.dim, device=device)\n",
    "        \n",
    "        decoder_tokens[batch_range, unmasked_indices] = encoded_tokens\n",
    "        decoder_tokens[batch_range, masked_indices] = mask_tokens\n",
    "\n",
    "        # attend with decoder\n",
    "        decoded_tokens = self.decoder(decoder_tokens)\n",
    "\n",
    "        # splice out the pred_features and pred_values\n",
    "        mask_tokens = decoded_tokens[batch_range, masked_indices]\n",
    "        pred_values = self.to_seqs(mask_tokens)\n",
    "        p = mask_tokens.mean(dim=1)\n",
    "\n",
    "        # calculate reconstruction loss\n",
    "        recon_loss = self.loss(pred_values, masked_patches)\n",
    "        # criterion = - (z.detach().softmax(dim=1) * p.log_softmax(dim=1)).mean()\n",
    "        criterion = -self.criterion(p, z.detach()).mean()\n",
    "        # criterion = self.ContrastiveLoss(p, z.detach())\n",
    "        \n",
    "        return criterion + recon_loss\n",
    "    \n",
    "model = MAE(seq_len=data[0][0].shape[1], \n",
    "            channels=2, \n",
    "            patch_size=patch_size,\n",
    "            cls_token=False,)\n",
    "\n",
    "# define optimizer\n",
    "opt = optim.AdamW(model.parameters())\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "# define function to training\n",
    "def Training(model, num_epochs, opt=opt, data_dl=loader):\n",
    "    loss_history = []\n",
    "    start_time = time.time()\n",
    "    path2weights = './models/SIGMA_hESC1000+Non-Specific.pt'\n",
    "    best_loss = 1e+7\n",
    "    \n",
    "    # 模型输出和loss计算\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for i, (x, _) in enumerate(tqdm(data_dl)):\n",
    "            # retrieve query and key`````\n",
    "            x = x.float().to(device, non_blocking=True)\n",
    "            # compute output and loss\n",
    "            with amp.autocast():\n",
    "                loss = model(x)\n",
    "                if loss == torch.nan:\n",
    "                    break\n",
    "                opt.zero_grad()\n",
    "            # compute gradient and do SGD step\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scale = scaler.get_scale()\n",
    "                scaler.update()\n",
    "#             loss.backward()\n",
    "#             opt.step()\n",
    "            running_loss += loss\n",
    "            \n",
    "        if loss == torch.nan:\n",
    "            break\n",
    "        # store loss history\n",
    "        epoch_loss = running_loss / (i+1)\n",
    "        loss_history.append(epoch_loss.detach().cpu().numpy())\n",
    "        print('train loss: %.6f, time: %.2f min' %(epoch_loss,(time.time()-start_time)/60))\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    # save weights\n",
    "    torch.save(model.state_dict(), path2weights)\n",
    "    best_encoder = nn.Sequential(copy.deepcopy(best_model.to_patch),\n",
    "                            copy.deepcopy(best_model.patch_to_emb),\n",
    "                            copy.deepcopy(best_model.encoder),\n",
    "                            # copy.deepcopy(best_model.ln),\n",
    "                            copy.deepcopy(best_model.logits))\n",
    "    # projector = copy.deepcopy(encoder.spatial.fc)# .fc\n",
    "    torch.cuda.empty_cache()  # 释放显存\n",
    "    return best_encoder, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create folder to save model weights\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "        \n",
    "# start training\n",
    "num_epochs = 200\n",
    "encoder, loss_history = Training(model.to(device), num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "plt.title('Loss History')\n",
    "plt.plot(range(1, num_epochs+1), loss_history, label='train')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Linear Classifier for transfer learning\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, backbone, finetune=True):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        dim = self.backbone[1][0].weight.shape[0]\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, 1)\n",
    "#         self.bn2 = nn.BatchNorm1d(dim)\n",
    "#         self.relu2 = nn.ReLU(inplace=True)\n",
    "#         self.fc3 = nn.Linear(dim, 1)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if finetune:\n",
    "            self.ft = finetune\n",
    "        else:\n",
    "            self.ft = finetune\n",
    "            for name, param in self.backbone.named_parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.ft:\n",
    "            x = self.backbone(x)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                x = self.backbone(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def downstream(model, linear_epoch=100):\n",
    "    loss_hist = {'train':[], 'val':[]}\n",
    "    start_time = time.time()\n",
    "    path2weights = './models/lincls_weights.pt'\n",
    "    max_auc = 0\n",
    "    auc = 0\n",
    "    from sklearn import metrics\n",
    "    linear_scaler = amp.GradScaler()#weight=torch.FloatTensor(class_weight).to(device)\n",
    "    linear_loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([class_weight[1]]).to(device))#nn.CrossEntropyLoss(weight=torch.HalfTensor(class_weight).to(device))\n",
    "    # linear_opt =  optim.SGD(encoder.parameters(), lr=30, momentum=0.9, weight_decay=1e-4)#pos_weight=torch.FloatTensor(class_weight[1]).to(device)\n",
    "    linear_opt =  optim.AdamW(model.parameters())\n",
    "    # start training\n",
    "    best_result = 0\n",
    "    for epoch in range(linear_epoch):\n",
    "        # clear_output()\n",
    "        print('Epoch {}/{}'.format(epoch+1, linear_epoch))\n",
    "    \n",
    "        running_train_loss = 0\n",
    "        running_val_loss = 0\n",
    "        running_test_loss = 0\n",
    "        train_pred, train_gold = [], []\n",
    "        val_pred, val_gold = [], []\n",
    "        # transfer dataloader\n",
    "        model.train()\n",
    "        for i, (x, y) in enumerate(tqdm(train_dl)):\n",
    "            # retrieve query and key\n",
    "            x = x.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            # extract features using linear_encoder\n",
    "            with amp.autocast():\n",
    "                pred = model(x)#.reshape(-1,)\n",
    "                loss = linear_loss_func(pred, y.reshape(-1,1))\n",
    "                if loss == torch.nan:\n",
    "                    break\n",
    "                linear_opt.zero_grad()\n",
    "                linear_scaler.scale(loss).backward()\n",
    "                linear_scaler.step(linear_opt)\n",
    "                linear_scale = linear_scaler.get_scale()\n",
    "                linear_scaler.update()\n",
    "            temp_pos = y.int().detach().cpu().numpy()\n",
    "            train_pred.extend(pred.detach().cpu().numpy())\n",
    "            train_gold.extend(temp_pos)\n",
    "            running_train_loss += loss\n",
    "            \n",
    "        if loss == torch.nan:\n",
    "            break\n",
    "        train_loss = running_train_loss / (i+1)\n",
    "        loss_hist['train'].append(train_loss.detach().cpu().numpy())\n",
    "        train_pred, train_gold = np.array(train_pred).reshape(-1), np.array(train_gold).reshape(-1)\n",
    "        train_AUROC = metrics.roc_auc_score(train_gold, train_pred)\n",
    "        train_AUPR = metrics.average_precision_score(train_gold, train_pred)\n",
    "        # validation dataloader\n",
    "        model.eval()\n",
    "        for i, (x, y) in enumerate(val_dl):\n",
    "            x = x.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                with amp.autocast():\n",
    "                    pred = model(x)\n",
    "                    running_val_loss += loss\n",
    "                val_pred.extend(pred.detach().cpu().numpy())\n",
    "                val_gold.extend(y.int().detach().cpu().numpy())\n",
    "        val_pred, val_gold = np.nan_to_num(val_pred).reshape(-1), np.nan_to_num(val_gold).reshape(-1)\n",
    "        val_AUROC = metrics.roc_auc_score(val_gold, val_pred)\n",
    "        val_AUPR = metrics.average_precision_score(val_gold, val_pred)\n",
    "        \n",
    "        val_loss = running_val_loss / (i+1)\n",
    "        loss_hist['val'].append(val_loss.detach().cpu().numpy())\n",
    "        print('train loss: %.6f, val loss: %.6f, AUROC score: %.4f, AUPR score: %.4f, time: %.4f min' %(train_loss, val_loss, val_AUROC, val_AUPR, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "        if val_AUPR > best_result:\n",
    "            best_loss = val_AUPR\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "    best_model.eval()\n",
    "    test_pred, test_gold = [], []\n",
    "    for i, (x, y) in enumerate(tqdm(test_dl)):\n",
    "        # retrieve query and key\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        # extract features using q_encoder\n",
    "        with torch.no_grad():\n",
    "            with amp.autocast():\n",
    "                linear_opt.zero_grad()\n",
    "                pred = best_model(x)# .reshape(-1,)\n",
    "                loss = linear_loss_func(pred, y.reshape(-1,1))\n",
    "            test_pred.extend(pred.detach().cpu().numpy())\n",
    "            test_gold.extend(y.int().detach().cpu().numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    test_loss = running_test_loss / (i+1)\n",
    "    test_pred, test_gold = np.nan_to_num(test_pred).reshape(-1), np.nan_to_num(test_gold).reshape(-1)\n",
    "    AUROC = metrics.roc_auc_score(test_gold, test_pred)\n",
    "    AUPR = metrics.average_precision_score(test_gold, test_pred)\n",
    "    # F1 = metrics.f1_score(test_gold, test_pred)\n",
    "    # BAS = metrics.balanced_accuracy_score(test_gold, test_pred)\n",
    "    # Accuracy = metrics.accuracy_score(test_gold, test_pred)\n",
    "    print('Test Metric:',AUROC, AUPR)\n",
    "    return [AUROC, AUPR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5-fold test\n",
    "train_index, val_index, test_index = split_datasets(labels)\n",
    "exp_train = np.array(all_exp)[np.array(train_index)]\n",
    "y_train = np.array(labels)[np.array(train_index)]\n",
    "exp_val = np.array(all_exp)[np.array(val_index)]\n",
    "y_val = np.array(labels)[np.array(val_index)]\n",
    "exp_test = np.array(all_exp)[np.array(test_index)]\n",
    "y_test = np.array(labels)[np.array(test_index)]\n",
    "\n",
    "train_data = Feeder(np.array(exp_train), y_train, patch_size, 'lincls')\n",
    "val_data = Feeder(np.array(exp_val), y_val, patch_size, 'lincls')\n",
    "test_data = Feeder(np.array(exp_test), y_test, patch_size, 'lincls')\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# without finetune (frozen backbone params)\n",
    "Metric = downstream(model=LinearClassifier(backbone=copy.deepcopy(encoder), finetune=False).to(device), linear_epoch=100)\n",
    "# with finetune (unfrozen backbone params)\n",
    "# Metric = downstream(model=LinearClassifier(backbone=copy.deepcopy(encoder), finetune=True).to(device), linear_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Metric, np.mean(TestMetric, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
